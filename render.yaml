services:
  - type: web
    name: gguf-openai-server
    env: docker
    plan: free
    autoDeploy: true
    envVars:
      - key: PORT
        value: "10000"
      - key: API_KEY
        sync: false
      - key: RATE_LIMIT
        value: "30/minute"
      - key: RAG_DB_PATH
        value: "./data/rag.db"
      - key: RAG_USE_LLM
        value: "1"
      # You can use MODEL_URL on Render if you host the GGUF somewhere:
      # - key: MODEL_URL
      #   sync: false
      # Or attach a persistent disk & set MODEL_PATH accordingly.
